{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08 - Corpus Analysis for RAG\n",
        "\n",
        "Analyze the Teamleader Focus documentation corpus before building the RAG system.\n",
        "\n",
        "**Goals:**\n",
        "- Understand document size distribution (chars, words, tokens)\n",
        "- Identify empty/thin documents (Training Videos, etc.)\n",
        "- Estimate embedding costs\n",
        "- Project LLM enrichment costs\n",
        "- Category/section breakdown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Try to import yaml, fall back to simple parser if not available\n",
        "try:\n",
        "    import yaml\n",
        "    HAS_YAML = True\n",
        "except ImportError:\n",
        "    print(\"PyYAML not found. Install with: pip install pyyaml\")\n",
        "    print(\"Using simple frontmatter parser instead.\")\n",
        "    HAS_YAML = False\n",
        "\n",
        "# For visualization\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    HAS_VIZ = True\n",
        "except ImportError:\n",
        "    print(\"Install pandas and matplotlib for visualizations: pip install pandas matplotlib\")\n",
        "    HAS_VIZ = False"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'yaml'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter, defaultdict\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# For visualization\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load All Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DOCS_DIR = Path('.')  # Assuming notebook is in DOCS folder\n",
        "\n",
        "def parse_frontmatter_simple(yaml_text: str) -> dict:\n",
        "    \"\"\"Simple YAML parser for frontmatter (fallback when PyYAML not available).\"\"\"\n",
        "    result = {}\n",
        "    for line in yaml_text.strip().split('\\n'):\n",
        "        if ':' in line:\n",
        "            key, _, value = line.partition(':')\n",
        "            key = key.strip()\n",
        "            value = value.strip().strip('\"').strip(\"'\")\n",
        "            if value:\n",
        "                result[key] = value\n",
        "    return result\n",
        "\n",
        "def parse_frontmatter(content: str) -> tuple[dict, str]:\n",
        "    \"\"\"Extract YAML frontmatter and body from markdown content.\"\"\"\n",
        "    if content.startswith('---'):\n",
        "        parts = content.split('---', 2)\n",
        "        if len(parts) >= 3:\n",
        "            try:\n",
        "                if HAS_YAML:\n",
        "                    frontmatter = yaml.safe_load(parts[1])\n",
        "                else:\n",
        "                    frontmatter = parse_frontmatter_simple(parts[1])\n",
        "                body = parts[2].strip()\n",
        "                return frontmatter or {}, body\n",
        "            except Exception:\n",
        "                pass\n",
        "    return {}, content\n",
        "\n",
        "def estimate_tokens(text: str) -> int:\n",
        "    \"\"\"Estimate token count (~4 chars per token for English).\"\"\"\n",
        "    return len(text) // 4\n",
        "\n",
        "def count_words(text: str) -> int:\n",
        "    \"\"\"Count words in text.\"\"\"\n",
        "    return len(text.split())\n",
        "\n",
        "def count_images(content: str) -> int:\n",
        "    \"\"\"Count markdown image references.\"\"\"\n",
        "    return len(re.findall(r'!\\[[^\\]]*\\]\\([^)]+\\)', content))\n",
        "\n",
        "def count_links(content: str) -> int:\n",
        "    \"\"\"Count markdown links (not images).\"\"\"\n",
        "    # Match [text](url) but not ![text](url)\n",
        "    return len(re.findall(r'(?<!!)\\[[^\\]]+\\]\\([^)]+\\)', content))\n",
        "\n",
        "def count_headers(content: str) -> int:\n",
        "    \"\"\"Count markdown headers.\"\"\"\n",
        "    return len(re.findall(r'^#{1,6}\\s', content, re.MULTILINE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find all markdown files\n",
        "md_files = sorted([\n",
        "    f for f in DOCS_DIR.rglob('*.md')\n",
        "    if not f.name.startswith('_') \n",
        "    and not f.name.startswith('.')\n",
        "    and not f.name.startswith('00_')  # Skip readme\n",
        "])\n",
        "\n",
        "print(f\"Found {len(md_files)} markdown files\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parse all documents\n",
        "documents = []\n",
        "\n",
        "for md_file in md_files:\n",
        "    with open(md_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    frontmatter, body = parse_frontmatter(content)\n",
        "    \n",
        "    # Get relative path from DOCS folder\n",
        "    rel_path = md_file.relative_to(DOCS_DIR)\n",
        "    \n",
        "    # Extract category from path or frontmatter\n",
        "    path_parts = rel_path.parts\n",
        "    category = frontmatter.get('category') or (path_parts[0] if len(path_parts) > 1 else 'Unknown')\n",
        "    section = frontmatter.get('section') or (path_parts[1] if len(path_parts) > 2 else 'Unknown')\n",
        "    \n",
        "    doc = {\n",
        "        'path': str(rel_path),\n",
        "        'filename': md_file.name,\n",
        "        'category': category,\n",
        "        'section': section,\n",
        "        'title': frontmatter.get('title', md_file.stem),\n",
        "        'url': frontmatter.get('url', ''),\n",
        "        'full_content': content,\n",
        "        'body': body,\n",
        "        'chars': len(body),\n",
        "        'words': count_words(body),\n",
        "        'tokens_est': estimate_tokens(body),\n",
        "        'images': count_images(content),\n",
        "        'links': count_links(content),\n",
        "        'headers': count_headers(body),\n",
        "        'has_frontmatter': bool(frontmatter),\n",
        "    }\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"Parsed {len(documents)} documents\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Overall Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_chars = sum(d['chars'] for d in documents)\n",
        "total_words = sum(d['words'] for d in documents)\n",
        "total_tokens = sum(d['tokens_est'] for d in documents)\n",
        "total_images = sum(d['images'] for d in documents)\n",
        "total_links = sum(d['links'] for d in documents)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"OVERALL CORPUS STATISTICS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total documents:        {len(documents):,}\")\n",
        "print(f\"Total characters:       {total_chars:,}\")\n",
        "print(f\"Total words:            {total_words:,}\")\n",
        "print(f\"Total tokens (est):     {total_tokens:,}\")\n",
        "print(f\"Total images:           {total_images:,}\")\n",
        "print(f\"Total internal links:   {total_links:,}\")\n",
        "print()\n",
        "print(f\"Avg chars/doc:          {total_chars // len(documents):,}\")\n",
        "print(f\"Avg words/doc:          {total_words // len(documents):,}\")\n",
        "print(f\"Avg tokens/doc:         {total_tokens // len(documents):,}\")\n",
        "print(f\"Avg images/doc:         {total_images / len(documents):.1f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Size Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Size buckets\n",
        "def size_bucket(tokens: int) -> str:\n",
        "    if tokens == 0:\n",
        "        return \"Empty (0)\"\n",
        "    elif tokens < 50:\n",
        "        return \"Tiny (<50)\"\n",
        "    elif tokens < 200:\n",
        "        return \"Small (50-200)\"\n",
        "    elif tokens < 500:\n",
        "        return \"Medium (200-500)\"\n",
        "    elif tokens < 1000:\n",
        "        return \"Large (500-1000)\"\n",
        "    elif tokens < 2000:\n",
        "        return \"Very Large (1000-2000)\"\n",
        "    else:\n",
        "        return \"Huge (2000+)\"\n",
        "\n",
        "# Categorize documents\n",
        "for doc in documents:\n",
        "    doc['size_bucket'] = size_bucket(doc['tokens_est'])\n",
        "\n",
        "# Count by bucket\n",
        "bucket_order = [\"Empty (0)\", \"Tiny (<50)\", \"Small (50-200)\", \"Medium (200-500)\", \n",
        "                \"Large (500-1000)\", \"Very Large (1000-2000)\", \"Huge (2000+)\"]\n",
        "bucket_counts = Counter(d['size_bucket'] for d in documents)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DOCUMENT SIZE DISTRIBUTION (by estimated tokens)\")\n",
        "print(\"=\" * 50)\n",
        "for bucket in bucket_order:\n",
        "    count = bucket_counts.get(bucket, 0)\n",
        "    pct = count / len(documents) * 100\n",
        "    bar = '█' * int(pct / 2)\n",
        "    print(f\"{bucket:25} {count:4} ({pct:5.1f}%) {bar}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if HAS_VIZ:\n",
        "    df = pd.DataFrame(documents)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    \n",
        "    # Histogram of tokens\n",
        "    axes[0].hist(df['tokens_est'], bins=50, edgecolor='black', alpha=0.7)\n",
        "    axes[0].set_xlabel('Tokens (estimated)')\n",
        "    axes[0].set_ylabel('Number of documents')\n",
        "    axes[0].set_title('Token Distribution')\n",
        "    axes[0].axvline(x=df['tokens_est'].median(), color='red', linestyle='--', label=f'Median: {df[\"tokens_est\"].median():.0f}')\n",
        "    axes[0].legend()\n",
        "    \n",
        "    # Histogram of words\n",
        "    axes[1].hist(df['words'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
        "    axes[1].set_xlabel('Words')\n",
        "    axes[1].set_ylabel('Number of documents')\n",
        "    axes[1].set_title('Word Count Distribution')\n",
        "    axes[1].axvline(x=df['words'].median(), color='red', linestyle='--', label=f'Median: {df[\"words\"].median():.0f}')\n",
        "    axes[1].legend()\n",
        "    \n",
        "    # Box plot by category\n",
        "    top_categories = df['category'].value_counts().head(5).index.tolist()\n",
        "    df_top = df[df['category'].isin(top_categories)]\n",
        "    df_top.boxplot(column='tokens_est', by='category', ax=axes[2])\n",
        "    axes[2].set_xlabel('Category')\n",
        "    axes[2].set_ylabel('Tokens')\n",
        "    axes[2].set_title('Token Distribution by Category')\n",
        "    plt.suptitle('')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Empty & Thin Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find empty and thin documents\n",
        "empty_docs = [d for d in documents if d['tokens_est'] == 0]\n",
        "tiny_docs = [d for d in documents if 0 < d['tokens_est'] < 50]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"EMPTY DOCUMENTS (0 tokens in body)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Count: {len(empty_docs)}\")\n",
        "print()\n",
        "\n",
        "# Group by category\n",
        "empty_by_cat = Counter(d['category'] for d in empty_docs)\n",
        "for cat, count in empty_by_cat.most_common():\n",
        "    print(f\"  {cat}: {count}\")\n",
        "\n",
        "print()\n",
        "print(\"Sample empty docs:\")\n",
        "for doc in empty_docs[:10]:\n",
        "    print(f\"  - {doc['path']}\")\n",
        "if len(empty_docs) > 10:\n",
        "    print(f\"  ... and {len(empty_docs) - 10} more\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"TINY DOCUMENTS (<50 tokens - likely just title or stub)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Count: {len(tiny_docs)}\")\n",
        "print()\n",
        "\n",
        "# Group by category\n",
        "tiny_by_cat = Counter(d['category'] for d in tiny_docs)\n",
        "for cat, count in tiny_by_cat.most_common():\n",
        "    print(f\"  {cat}: {count}\")\n",
        "\n",
        "print()\n",
        "print(\"Sample tiny docs:\")\n",
        "for doc in tiny_docs[:10]:\n",
        "    print(f\"  - {doc['path']} ({doc['words']} words)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quality assessment\n",
        "def assess_quality(doc: dict) -> str:\n",
        "    \"\"\"Assess document quality for RAG.\"\"\"\n",
        "    if doc['tokens_est'] == 0:\n",
        "        return 'empty'\n",
        "    elif doc['tokens_est'] < 50:\n",
        "        return 'stub'\n",
        "    elif doc['category'] == 'Training Videos' and doc['tokens_est'] < 100:\n",
        "        return 'video_reference'\n",
        "    else:\n",
        "        return 'useful'\n",
        "\n",
        "for doc in documents:\n",
        "    doc['quality'] = assess_quality(doc)\n",
        "\n",
        "quality_counts = Counter(d['quality'] for d in documents)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"QUALITY ASSESSMENT\")\n",
        "print(\"=\" * 50)\n",
        "for quality in ['useful', 'video_reference', 'stub', 'empty']:\n",
        "    count = quality_counts.get(quality, 0)\n",
        "    pct = count / len(documents) * 100\n",
        "    print(f\"{quality:20} {count:4} ({pct:5.1f}%)\")\n",
        "\n",
        "useful_docs = [d for d in documents if d['quality'] == 'useful']\n",
        "print(f\"\\nUseful docs for RAG: {len(useful_docs)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Category & Section Breakdown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Category breakdown\n",
        "category_counts = Counter(d['category'] for d in documents)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DOCUMENTS BY CATEGORY\")\n",
        "print(\"=\" * 50)\n",
        "for cat, count in category_counts.most_common():\n",
        "    pct = count / len(documents) * 100\n",
        "    # Calculate avg tokens for this category\n",
        "    cat_docs = [d for d in documents if d['category'] == cat]\n",
        "    avg_tokens = sum(d['tokens_est'] for d in cat_docs) // len(cat_docs) if cat_docs else 0\n",
        "    print(f\"{cat:25} {count:4} ({pct:5.1f}%)  avg tokens: {avg_tokens:,}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if HAS_VIZ:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Pie chart of categories\n",
        "    cats = [c for c, _ in category_counts.most_common(6)]\n",
        "    counts = [category_counts[c] for c in cats]\n",
        "    other = sum(category_counts[c] for c in category_counts if c not in cats)\n",
        "    if other > 0:\n",
        "        cats.append('Other')\n",
        "        counts.append(other)\n",
        "    \n",
        "    axes[0].pie(counts, labels=cats, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0].set_title('Documents by Category')\n",
        "    \n",
        "    # Bar chart of quality by category\n",
        "    if HAS_VIZ:\n",
        "        df = pd.DataFrame(documents)\n",
        "        quality_cat = df.groupby(['category', 'quality']).size().unstack(fill_value=0)\n",
        "        quality_cat = quality_cat.reindex(columns=['useful', 'video_reference', 'stub', 'empty'], fill_value=0)\n",
        "        quality_cat.head(10).plot(kind='barh', stacked=True, ax=axes[1], \n",
        "                                   color=['#2ecc71', '#f39c12', '#e74c3c', '#95a5a6'])\n",
        "        axes[1].set_xlabel('Number of documents')\n",
        "        axes[1].set_title('Quality Distribution by Category')\n",
        "        axes[1].legend(title='Quality')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Longest & Shortest Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sort by tokens\n",
        "sorted_by_tokens = sorted(documents, key=lambda d: d['tokens_est'], reverse=True)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TOP 15 LONGEST DOCUMENTS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Tokens':<8} {'Words':<8} {'Category':<20} {'Title (truncated)'}\")\n",
        "print(\"-\" * 70)\n",
        "for doc in sorted_by_tokens[:15]:\n",
        "    title = doc['title'][:40] + '...' if len(doc['title']) > 40 else doc['title']\n",
        "    print(f\"{doc['tokens_est']:<8} {doc['words']:<8} {doc['category'][:20]:<20} {title}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check if any docs exceed embedding model limits\n",
        "EMBEDDING_LIMIT = 8191  # text-embedding-3-small limit\n",
        "\n",
        "over_limit = [d for d in documents if d['tokens_est'] > EMBEDDING_LIMIT]\n",
        "near_limit = [d for d in documents if EMBEDDING_LIMIT * 0.8 < d['tokens_est'] <= EMBEDDING_LIMIT]\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"EMBEDDING MODEL LIMIT CHECK ({EMBEDDING_LIMIT:,} tokens)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Documents over limit:    {len(over_limit)}\")\n",
        "print(f\"Documents near limit (80%+): {len(near_limit)}\")\n",
        "\n",
        "if over_limit:\n",
        "    print(\"\\nDocuments exceeding limit:\")\n",
        "    for doc in over_limit:\n",
        "        print(f\"  - {doc['path']} ({doc['tokens_est']:,} tokens)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cost Projections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Embedding costs (OpenAI text-embedding-3-small)\n",
        "# Price: $0.02 per 1M tokens\n",
        "EMBEDDING_COST_PER_M = 0.02\n",
        "\n",
        "# Only count useful documents\n",
        "useful_docs = [d for d in documents if d['quality'] == 'useful']\n",
        "useful_tokens = sum(d['tokens_est'] for d in useful_docs)\n",
        "\n",
        "# For full-doc embedding, we also add metadata header (~50 tokens per doc)\n",
        "metadata_overhead = len(useful_docs) * 50\n",
        "total_embedding_tokens = useful_tokens + metadata_overhead\n",
        "\n",
        "embedding_cost = (total_embedding_tokens / 1_000_000) * EMBEDDING_COST_PER_M\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"EMBEDDING COST PROJECTION\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Useful documents:        {len(useful_docs)}\")\n",
        "print(f\"Content tokens:          {useful_tokens:,}\")\n",
        "print(f\"Metadata overhead:       {metadata_overhead:,} (~50/doc)\")\n",
        "print(f\"Total tokens to embed:   {total_embedding_tokens:,}\")\n",
        "print(f\"\")\n",
        "print(f\"Model: text-embedding-3-small\")\n",
        "print(f\"Price: ${EMBEDDING_COST_PER_M}/1M tokens\")\n",
        "print(f\"\")\n",
        "print(f\"Estimated cost: ${embedding_cost:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LLM Enrichment costs (generating summary, keywords, quality flags)\n",
        "# Using Gemini Flash via OpenRouter\n",
        "\n",
        "# Gemini 2.0 Flash pricing (OpenRouter): $0.10 input / $0.40 output per 1M tokens\n",
        "LLM_INPUT_COST_PER_M = 0.10\n",
        "LLM_OUTPUT_COST_PER_M = 0.40\n",
        "\n",
        "# Estimate: ~500 tokens for prompt template + document content\n",
        "# Output: ~100 tokens (summary + keywords + quality)\n",
        "PROMPT_OVERHEAD = 300  # System prompt, instructions\n",
        "OUTPUT_TOKENS = 100  # Generated summary, keywords, quality\n",
        "\n",
        "total_input_tokens = sum(d['tokens_est'] + PROMPT_OVERHEAD for d in useful_docs)\n",
        "total_output_tokens = len(useful_docs) * OUTPUT_TOKENS\n",
        "\n",
        "input_cost = (total_input_tokens / 1_000_000) * LLM_INPUT_COST_PER_M\n",
        "output_cost = (total_output_tokens / 1_000_000) * LLM_OUTPUT_COST_PER_M\n",
        "total_llm_cost = input_cost + output_cost\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"LLM ENRICHMENT COST PROJECTION\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Documents to process:    {len(useful_docs)}\")\n",
        "print(f\"\")\n",
        "print(f\"Input tokens:            {total_input_tokens:,}\")\n",
        "print(f\"  - Document content:    {useful_tokens:,}\")\n",
        "print(f\"  - Prompt overhead:     {PROMPT_OVERHEAD * len(useful_docs):,}\")\n",
        "print(f\"Output tokens:           {total_output_tokens:,}\")\n",
        "print(f\"\")\n",
        "print(f\"Model: Gemini 2.0 Flash (via OpenRouter)\")\n",
        "print(f\"Price: ${LLM_INPUT_COST_PER_M}/1M input, ${LLM_OUTPUT_COST_PER_M}/1M output\")\n",
        "print(f\"\")\n",
        "print(f\"Input cost:              ${input_cost:.2f}\")\n",
        "print(f\"Output cost:             ${output_cost:.2f}\")\n",
        "print(f\"Total LLM cost:          ${total_llm_cost:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Alternative: Claude Haiku pricing\n",
        "CLAUDE_INPUT_COST_PER_M = 0.25\n",
        "CLAUDE_OUTPUT_COST_PER_M = 1.25\n",
        "\n",
        "claude_input_cost = (total_input_tokens / 1_000_000) * CLAUDE_INPUT_COST_PER_M\n",
        "claude_output_cost = (total_output_tokens / 1_000_000) * CLAUDE_OUTPUT_COST_PER_M\n",
        "claude_total = claude_input_cost + claude_output_cost\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"ALTERNATIVE: CLAUDE HAIKU COST\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Model: Claude 3.5 Haiku (via OpenRouter)\")\n",
        "print(f\"Price: ${CLAUDE_INPUT_COST_PER_M}/1M input, ${CLAUDE_OUTPUT_COST_PER_M}/1M output\")\n",
        "print(f\"\")\n",
        "print(f\"Input cost:              ${claude_input_cost:.2f}\")\n",
        "print(f\"Output cost:             ${claude_output_cost:.2f}\")\n",
        "print(f\"Total Claude cost:       ${claude_total:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Total cost summary\n",
        "print(\"=\" * 50)\n",
        "print(\"TOTAL COST SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\")\n",
        "print(f\"Option A: Gemini Flash + Embeddings\")\n",
        "print(f\"  LLM enrichment:        ${total_llm_cost:.2f}\")\n",
        "print(f\"  Embeddings:            ${embedding_cost:.2f}\")\n",
        "print(f\"  TOTAL:                 ${total_llm_cost + embedding_cost:.2f}\")\n",
        "print(f\"\")\n",
        "print(f\"Option B: Claude Haiku + Embeddings\")\n",
        "print(f\"  LLM enrichment:        ${claude_total:.2f}\")\n",
        "print(f\"  Embeddings:            ${embedding_cost:.2f}\")\n",
        "print(f\"  TOTAL:                 ${claude_total + embedding_cost:.2f}\")\n",
        "print(f\"\")\n",
        "print(f\"Option C: No LLM enrichment (metadata only)\")\n",
        "print(f\"  Embeddings only:       ${embedding_cost:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Content Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze document types by title patterns\n",
        "def classify_doc_type(title: str) -> str:\n",
        "    title_lower = title.lower()\n",
        "    if title_lower.startswith('how to'):\n",
        "        return 'How To'\n",
        "    elif title_lower.startswith('faq'):\n",
        "        return 'FAQ'\n",
        "    elif title_lower.startswith('getting started'):\n",
        "        return 'Getting Started'\n",
        "    elif title_lower.startswith('video'):\n",
        "        return 'Video'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "for doc in documents:\n",
        "    doc['doc_type'] = classify_doc_type(doc['title'])\n",
        "\n",
        "type_counts = Counter(d['doc_type'] for d in documents)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DOCUMENT TYPES (by title pattern)\")\n",
        "print(\"=\" * 50)\n",
        "for doc_type, count in type_counts.most_common():\n",
        "    pct = count / len(documents) * 100\n",
        "    print(f\"{doc_type:20} {count:4} ({pct:5.1f}%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Documents with most images\n",
        "sorted_by_images = sorted(documents, key=lambda d: d['images'], reverse=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TOP 10 DOCUMENTS BY IMAGE COUNT\")\n",
        "print(\"=\" * 60)\n",
        "for doc in sorted_by_images[:10]:\n",
        "    title = doc['title'][:45] + '...' if len(doc['title']) > 45 else doc['title']\n",
        "    print(f\"{doc['images']:3} images  {title}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Documents with most internal links (good for relationship mapping)\n",
        "sorted_by_links = sorted(documents, key=lambda d: d['links'], reverse=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TOP 10 DOCUMENTS BY INTERNAL LINK COUNT\")\n",
        "print(\"=\" * 60)\n",
        "for doc in sorted_by_links[:10]:\n",
        "    title = doc['title'][:45] + '...' if len(doc['title']) > 45 else doc['title']\n",
        "    print(f\"{doc['links']:3} links   {title}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Export Analysis Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Export summary for next steps\n",
        "analysis_summary = {\n",
        "    'total_documents': len(documents),\n",
        "    'useful_documents': len(useful_docs),\n",
        "    'empty_documents': len(empty_docs),\n",
        "    'tiny_documents': len(tiny_docs),\n",
        "    'total_tokens': total_tokens,\n",
        "    'useful_tokens': useful_tokens,\n",
        "    'avg_tokens_per_doc': total_tokens // len(documents),\n",
        "    'documents_over_embedding_limit': len(over_limit),\n",
        "    'cost_estimates': {\n",
        "        'embeddings': round(embedding_cost, 2),\n",
        "        'llm_enrichment_gemini': round(total_llm_cost, 2),\n",
        "        'llm_enrichment_claude': round(claude_total, 2),\n",
        "        'total_gemini': round(total_llm_cost + embedding_cost, 2),\n",
        "        'total_claude': round(claude_total + embedding_cost, 2),\n",
        "    },\n",
        "    'quality_breakdown': dict(quality_counts),\n",
        "    'category_breakdown': dict(category_counts),\n",
        "    'size_distribution': dict(bucket_counts),\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "output_path = DOCS_DIR / '08_corpus_analysis.json'\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(analysis_summary, f, indent=2)\n",
        "\n",
        "print(f\"Analysis saved to: {output_path}\")\n",
        "print()\n",
        "print(json.dumps(analysis_summary, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"RECOMMENDATIONS FOR RAG IMPLEMENTATION\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "print(\"1. DOCUMENT FILTERING\")\n",
        "print(f\"   - Exclude {len(empty_docs)} empty documents\")\n",
        "print(f\"   - Review {len(tiny_docs)} tiny documents (<50 tokens)\")\n",
        "print(f\"   - Consider flagging 'Training Videos' as video_reference\")\n",
        "print(f\"   - Final useful docs: {len(useful_docs)}\")\n",
        "print()\n",
        "\n",
        "print(\"2. CHUNKING STRATEGY\")\n",
        "if len(over_limit) == 0:\n",
        "    print(f\"   ✅ No documents exceed embedding limit ({EMBEDDING_LIMIT:,} tokens)\")\n",
        "    print(f\"   → Full document embedding is viable\")\n",
        "else:\n",
        "    print(f\"   ⚠️  {len(over_limit)} documents exceed limit\")\n",
        "    print(f\"   → Consider chunking for large documents\")\n",
        "print(f\"   - Median doc size: {sorted(d['tokens_est'] for d in documents)[len(documents)//2]:,} tokens\")\n",
        "print()\n",
        "\n",
        "print(\"3. COST OPTIMIZATION\")\n",
        "print(f\"   - Gemini Flash is cheapest: ~${total_llm_cost + embedding_cost:.2f} total\")\n",
        "print(f\"   - Skip LLM enrichment if budget tight: ~${embedding_cost:.2f}\")\n",
        "print()\n",
        "\n",
        "print(\"4. CONTENT QUALITY\")\n",
        "print(f\"   - {type_counts.get('How To', 0)} 'How To' guides (step-by-step)\")\n",
        "print(f\"   - {type_counts.get('FAQ', 0)} FAQ articles (Q&A format)\")\n",
        "print(f\"   - Rich internal linking ({total_links:,} links) for relationship context\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}